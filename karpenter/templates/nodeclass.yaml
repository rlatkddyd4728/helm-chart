apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: game
spec:
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "sy-kim-eks-cluster"
        env: "stg"
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "sy-kim-eks-cluster"
  amiFamily: AL2
  amiSelectorTerms:
    - name: amazon-eks-node-1.26-v20240110
  tags:
    Name: nv-dev-stg-node 
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi
        volumeType: gp3
        deleteOnTermination: true
        throughput: 125
  instanceProfile: "sy_kim-KarpenterNodeInstanceProfile"
  userData:  |
    MIME-Version: 1.0
    Content-Type: multipart/mixed; boundary="==MYBOUNDARY=="

    --==MYBOUNDARY==
    Content-Type: text/x-shellscript; charset="us-ascii"

    #!/bin/bash
    echo "Running custom user data script"

    export env=dev
    export prefix=nv
    export dev_id=sy_kim
    export region=ap-southeast-3
    export cluster=sy-kim-eks-cluster

    #=============================
    # hostname
    #=============================
    ng_name=$(aws ec2 describe-tags --filters "Name=resource-id,Values=$(wget -q -O - http://169.254.169.254/latest/meta-data/instance-id)" --query "Tags[?Key=='karpenter.sh/nodepool'].Value" --output text --region ap-southeast-3)

    resource_id=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)

    tag_name=${prefix}-${env}-${ng_name}-$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4 | cut -d. -f3,4 | sed s/"\."/"-"/g)   

    # hostnamectl set-hostname ${tag_name}

    #=============================
    # tag
    #=============================
    aws ec2 create-tags --resources ${resource_id} --tags Key=Name,Value=${tag_name} --region ${region}

    #=============================
    # useradd
    #=============================
    users=("${dev_id}" "rundeck")
    for user in "${users[@]}"; do
        if [ "$user" == "" ]; then
            continue
        fi
        useradd ${user}
        mkdir -m 700 /home/${user}/.ssh
        aws s3 cp s3://s3-sykim-ops/auth/${user}/id_rsa.pub /home/${user}/credentials/id_rsa.pub --region ${region}
        mv /home/${user}/credentials/id_rsa.pub /home/${user}/.ssh/authorized_keys
        rm -rf /home/${user}/credentials
        chmod 600 /home/$user/.ssh/authorized_keys
        chown -R ${user}:${user} /home/${user}/.ssh
        echo "${user}    ALL=(ALL)   NOPASSWD: ALL" > /etc/sudoers.d/${user}
    done

    #=============================
    # Add the kubelet garbage collection
    #=============================
    # Inject imageGCHighThresholdPercent value unless it has already been set.
    if ! grep -q imageGCHighThresholdPercent /etc/kubernetes/kubelet/kubelet-config.json; 
    then 
        sed -i '/"apiVersion*/a \ \ "imageGCHighThresholdPercent": 70,' /etc/kubernetes/kubelet/kubelet-config.json
    fi

    # Inject imageGCLowThresholdPercent value unless it has already been set.
    if ! grep -q imageGCLowThresholdPercent /etc/kubernetes/kubelet/kubelet-config.json; 
    then 
        sed -i '/"imageGCHigh*/a \ \ "imageGCLowThresholdPercent": 50,' /etc/kubernetes/kubelet/kubelet-config.json
    fi
    --==MYBOUNDARY==--
